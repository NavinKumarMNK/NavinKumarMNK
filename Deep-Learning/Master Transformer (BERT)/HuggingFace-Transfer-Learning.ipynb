{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c106ed",
   "metadata": {},
   "source": [
    "# **Transfer Learning in Transformers**\n",
    "## **Sarcasm Prediction using News Headlines** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82e620be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_metric\n",
    "from transformers import EarlyStoppingCallback, AdamW, get_scheduler, DataCollatorWithPadding, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268f2512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b7697",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08236d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"data/sarcasm_headlines/Sarcasm_Headlines_Dataset_v2.json\"\n",
    "df = pd.read_json(dataset, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd7c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e4c5588aeed38262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/mnk/.cache/huggingface/datasets/json/default-e4c5588aeed38262/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5961e93aaba411390da8f4e862f386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5664d508cc46421284a6ee03e4065e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f12d57814f4446f976b97e39e467d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/mnk/.cache/huggingface/datasets/json/default-e4c5588aeed38262/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cebceba82424ec59bedba83fed97048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['is_sarcastic', 'headline', 'article_link'],\n",
       "        num_rows: 28619\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hf = load_dataset('json', data_files=dataset)\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "754ff786",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hf=dataset_hf.remove_columns(['article_link'])\n",
    "dataset_hf.set_format('pandas')\n",
    "dataset_hf=dataset_hf['train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1253e795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['headline', 'label'],\n",
       "        num_rows: 22802\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['headline', 'label'],\n",
       "        num_rows: 2851\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['headline', 'label'],\n",
       "        num_rows: 2850\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hf.rename(columns={'is_sarcastic':'label'},inplace=True)\n",
    "dataset_hf.drop_duplicates(subset=['headline'],inplace=True)\n",
    "dataset_hf=dataset_hf.reset_index()[['headline', 'label']]\n",
    "dataset_hf=Dataset.from_pandas(dataset_hf)\n",
    "\n",
    "train_testvalid = dataset_hf.train_test_split(test_size=0.2,seed=15)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5,seed=15)\n",
    "\n",
    "dataset_hf = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "dataset_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46cef94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.model_max_len=512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92d1d8",
   "metadata": {},
   "source": [
    "## **Tokenize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98291e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9e2ff360504e3198f3e211410b4588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de870d43de8d48dabdadf77e6b5d805f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998f260a5fcb4a749d49d7d3cbfb5938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 22802\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2851\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2850\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'headline': \"dan harmon finally reveals reason behind 'rick and morty' delays\",\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  4907,\n",
       "  25546,\n",
       "  2633,\n",
       "  7657,\n",
       "  3114,\n",
       "  2369,\n",
       "  1005,\n",
       "  6174,\n",
       "  1998,\n",
       "  22294,\n",
       "  2100,\n",
       "  1005,\n",
       "  14350,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(data):\n",
    "  return tokenizer(data[\"headline\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset_hf.map(tokenize, batched=True)\n",
    "print(tokenized_dataset)\n",
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71a5b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': tensor([0, 0, 1]), 'input_ids': [tensor([  101,  4907, 25546,  2633,  7657,  3114,  2369,  1005,  6174,  1998,\n",
      "        22294,  2100,  1005, 14350,   102]), tensor([  101,  2654,  7800,  1997, 17077, 13318,  2111,   102]), tensor([  101, 13025,  1011,  3573,  7309,  2064,  1005,  1056,  4562,  2000,\n",
      "         4521,  2833,  4902,   102])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4907, 25546,  2633,  7657,  3114,  2369,  1005,  6174,  1998,\n",
       "         22294,  2100,  1005, 14350,   102],\n",
       "        [  101,  2654,  7800,  1997, 17077, 13318,  2111,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  101, 13025,  1011,  3573,  7309,  2064,  1005,  1056,  4562,  2000,\n",
       "          4521,  2833,  4902,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]), 'labels': tensor([0, 0, 1])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # A DataCollator that will dynamically pad the inputs received.\n",
    "data_collator\n",
    "\n",
    "print(tokenized_dataset['train'][:3])\n",
    "data_collator(tokenized_dataset['train'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933517a",
   "metadata": {},
   "source": [
    "## **Transfer Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ebc41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSpecificTransformerHead(nn.Module): \n",
    "    def __init__(self, checkpoint:str, num_labels:int):\n",
    "        super(TaskSpecificTransformerHead, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.model = AutoModel.from_pretrained(checkpoint, config =  AutoConfig.from_pretrained(checkpoint, output_attention = True, output_hidden_states = True)) \n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Linear(768, 256)\n",
    "                                        ,nn.ReLU()\n",
    "                                        ,nn.Dropout(0.1)\n",
    "                                        ,nn.Linear(256, self.num_labels)\n",
    "                                        ,nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, input_idx=None, attention_mask=None, labels=None):\n",
    "        transformer_output = self.model(input_idx, attention_mask=attention_mask)\n",
    "        logits = self.classifier(transformer_output[0][:, 0, :].view(-1, 768))\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss = loss_func(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=transformer_output.hidden_states, attentions=transformer_output.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66c12f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "task_specific_model = TaskSpecificTransformerHead(checkpoint, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0b6bb",
   "metadata": {},
   "source": [
    "## **PyTorch DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7af4907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['valid'], shuffle = True, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58fadc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([  101,  2654,  7800,  1997, 17077, 13318,  2111,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb98e9",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8246f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnk/python/envs/pytorch/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(task_specific_model.parameters(), lr = 1e-4 )\n",
    "num_epoch = 10\n",
    "num_training_steps = num_epoch * len(train_dataloader) # no_of_epochs * no_of_batches\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    ")\n",
    "\n",
    "metric = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f080aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results',          # output directory\n",
    "    num_train_epochs = num_epoch,              # total number of training epochs\n",
    "    per_device_train_batch_size = 32,  # batch size per device during training\n",
    "    per_device_eval_batch_size = 32,   # batch size for evaluation\n",
    "    warmup_steps = 500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay = 0.01,               # strength of weight decay\n",
    "    logging_dir = './logs',            # directory for storing logs\n",
    "    logging_steps = 10,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 100,\n",
    "    save_steps = 100,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"f1\",\n",
    "    greater_is_better = True,\n",
    "    fp16 = True,\n",
    "    dataloader_num_workers = 4,\n",
    "    run_name = \"sarcasm_headlines\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = task_specific_model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args = training_args,                  # training arguments, defined above\n",
    "    train_dataset = train_dataloader.dataset,         # training dataset\n",
    "    eval_dataset = eval_dataloader.dataset,             # evaluation dataset\n",
    "    compute_metrics = compute_metrics,         # define metrics function\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83781a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5561472a154534a29b01577274fb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8ad9a6fa7a4b89ab6bdca75bef0c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cfb5db13964858a52dd1a619abda9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8982591876208897}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aba376ef2a41be9d6252e77efcc93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207b14eb4a254c2a9fbe9d72bdb573f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9011827546737886}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedb229d5dda48ea9f126675eb46ac56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b429db821247cab169de8b5ffe4b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9081404032860343}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42bcab8623140389c10648fd6a315f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dba1fb20ef43aea6a497e08b12bf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9003516998827666}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b1900cb5fc4560b39e93972b18a252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mnk/MNK/Mega/MegNav/Deep-Learning/Master Transformer (BERT)/HuggingFace-Transfer-Learning.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mnk/MNK/Mega/MegNav/Deep-Learning/Master%20Transformer%20%28BERT%29/HuggingFace-Transfer-Learning.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m task_specific_model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mnk/MNK/Mega/MegNav/Deep-Learning/Master%20Transformer%20%28BERT%29/HuggingFace-Transfer-Learning.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_dataloader):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mnk/MNK/Mega/MegNav/Deep-Learning/Master%20Transformer%20%28BERT%29/HuggingFace-Transfer-Learning.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mnk/MNK/Mega/MegNav/Deep-Learning/Master%20Transformer%20%28BERT%29/HuggingFace-Transfer-Learning.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     input_ids \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mnk/MNK/Mega/MegNav/Deep-Learning/Master%20Transformer%20%28BERT%29/HuggingFace-Transfer-Learning.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/python/envs/pytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    277\u001b[0m     p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m foreach \u001b[39mor\u001b[39;00m p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mis_sparse):\n\u001b[0;32m--> 279\u001b[0m     p\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mzero_()\n\u001b[1;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     per_device_and_dtype_grads[p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdevice][p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdtype]\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mgrad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epoch)):\n",
    "    task_specific_model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        output = task_specific_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "    task_specific_model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        output = task_specific_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "        metric.add_batch(predictions=torch.argmax(logits, dim=-1), references=labels)\n",
    "    print(metric.compute())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9e74a",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "218bb61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9029931482149297}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_specific_model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = { k: v.to(device) for k, v in batch.items() }\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = task_specific_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim = -1)\n",
    "    metric.add_batch(predictions = predictions, references=batch['labels'] )\n",
    "    \n",
    "metric.compute()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ed60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c8b17707a87e86f58fc8e0e03557a8732d4849cf558d6d13f0acd878e2598f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
